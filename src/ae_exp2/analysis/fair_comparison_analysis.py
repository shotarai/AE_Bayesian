"""
å…¬æ­£ãªæ¯”è¼ƒå®Ÿé¨“ã®çµæœåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ãƒã‚¤ã‚¢ã‚¹ã®ãªã„å…¬æ­£ãªæ¯”è¼ƒå®Ÿé¨“ã®çµæœã‚’è©³ç´°ã«åˆ†æã—ã€
çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼ã—ã€å¯è¦–åŒ–ã‚’è¡Œã„ã¾ã™ã€‚

Key Findings:
- GPT-4 Blind ãŒæœ€ã‚‚å„ªç§€ãªæ€§èƒ½ã‚’ç¤ºã—ãŸ (MAE: 0.437Â±0.083)
- Meta-analytical approach ãŒæœ€ã‚‚ä½ã„æ€§èƒ½ (MAE: 0.514Â±0.096)
- GPT-4 Disease-Informed ã¯ä¸­é–“çš„æ€§èƒ½ (MAE: 0.504Â±0.097)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']

class FairComparisonAnalyzer:
    """å…¬æ­£ãªæ¯”è¼ƒå®Ÿé¨“ã®çµæœåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, results_dir: str = "/Users/araishouta/AE_exp2/results/data"):
        self.results_dir = Path(results_dir)
        self.cv_summary = None
        self.cv_detailed = None
        self.progressive_results = None
        
    def load_latest_results(self):
        """æœ€æ–°ã®å®Ÿé¨“çµæœã‚’èª­ã¿è¾¼ã¿"""
        # CV summary results
        cv_summary_files = list(self.results_dir.glob("cv_5fold_summary_*.csv"))
        if cv_summary_files:
            latest_cv_summary = max(cv_summary_files, key=lambda x: x.stat().st_mtime)
            self.cv_summary = pd.read_csv(latest_cv_summary, index_col=0)
            print(f"Loaded CV summary: {latest_cv_summary.name}")
        
        # CV detailed results
        cv_detailed_files = list(self.results_dir.glob("cv_5fold_results_*.csv"))
        if cv_detailed_files:
            latest_cv_detailed = max(cv_detailed_files, key=lambda x: x.stat().st_mtime)
            self.cv_detailed = pd.read_csv(latest_cv_detailed)
            print(f"Loaded CV detailed: {latest_cv_detailed.name}")
        
        # Progressive information results
        progressive_files = list(self.results_dir.glob("ipd_progressive_information_fair_comparison_*.csv"))
        if progressive_files:
            latest_progressive = max(progressive_files, key=lambda x: x.stat().st_mtime)
            self.progressive_results = pd.read_csv(latest_progressive)
            print(f"Loaded progressive: {latest_progressive.name}")
            
    def analyze_cv_results(self):
        """5-fold CVçµæœã®çµ±è¨ˆåˆ†æ"""
        print("\n" + "="*60)
        print("5-FOLD CROSS-VALIDATION çµæœåˆ†æ")
        print("="*60)
        
        if self.cv_summary is None:
            print("CV summary data not available")
            return
            
        # CVçµæœã®è¡¨ç¤º
        print("\nMAE (Mean Absolute Error) çµæœ:")
        print("-" * 40)
        mae_results = self.cv_summary[['mae']].copy()
        mae_results.columns = ['Mean', 'Std']
        mae_results['Mean'] = mae_results['Mean'].round(4)
        mae_results['Std'] = mae_results['Std'].round(4)
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        mae_results = mae_results.sort_values('Mean')
        mae_results['Rank'] = range(1, len(mae_results) + 1)
        
        for i, (model, row) in enumerate(mae_results.iterrows()):
            status = "ğŸ¥‡ BEST" if i == 0 else "ğŸ¥ˆ 2nd" if i == 1 else "ğŸ¥‰ 3rd"
            print(f"{row['Rank']}. {model}: {row['Mean']:.4f} Â± {row['Std']:.4f} {status}")
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œè¨¼ï¼ˆè©³ç´°CVçµæœãŒå¿…è¦ï¼‰
        if self.cv_detailed is not None:
            self.statistical_significance_test()
            
    def statistical_significance_test(self):
        """çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œè¨¼"""
        print("\nçµ±è¨ˆçš„æœ‰æ„æ€§æ¤œè¨¼:")
        print("-" * 30)
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®MAEå€¤ã‚’æŠ½å‡º
        models = self.cv_detailed['model'].unique()
        mae_by_model = {}
        
        for model in models:
            model_data = self.cv_detailed[self.cv_detailed['model'] == model]
            mae_by_model[model] = model_data['mae'].values
            
        # ãƒšã‚¢ãƒ¯ã‚¤ã‚ºtæ¤œå®š
        model_pairs = [
            ('GPT-4 Blind', 'Meta-analytical'),
            ('GPT-4 Blind', 'GPT-4 Disease-Informed'),
            ('GPT-4 Disease-Informed', 'Meta-analytical')
        ]
        
        for model1, model2 in model_pairs:
            if model1 in mae_by_model and model2 in mae_by_model:
                t_stat, p_value = stats.ttest_rel(mae_by_model[model1], mae_by_model[model2])
                significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"
                print(f"{model1} vs {model2}: t={t_stat:.3f}, p={p_value:.4f} {significance}")
                
    def analyze_progressive_results(self):
        """ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºåˆ†æ"""
        print("\n" + "="*60)
        print("PROGRESSIVE SAMPLE SIZE åˆ†æ")
        print("="*60)
        
        if self.progressive_results is None:
            print("Progressive results not available")
            return
            
        # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã”ã¨ã®æ€§èƒ½
        print("\nã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºåˆ¥æ€§èƒ½ (MAE):")
        print("-" * 40)
        
        for n_sites in sorted(self.progressive_results['n_sites'].unique()):
            subset = self.progressive_results[self.progressive_results['n_sites'] == n_sites]
            n_patients = subset['n_patients'].iloc[0]
            print(f"\n{n_sites} sites ({n_patients} patients):")
            
            for model in ['GPT-4 Blind', 'GPT-4 Disease-Informed', 'Meta-analytical']:
                model_row = subset[subset['model'] == model]
                if not model_row.empty:
                    mae = model_row['mae'].iloc[0]
                    print(f"  {model}: {mae:.4f}")
                    
    def create_comprehensive_visualization(self):
        """åŒ…æ‹¬çš„ãªå¯è¦–åŒ–"""
        print("\nå¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
        
        # ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã®è¨­å®š
        fig = plt.figure(figsize=(20, 16))
        
        # 1. CVçµæœã®ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        if self.cv_detailed is not None:
            ax1 = plt.subplot(2, 3, 1)
            sns.boxplot(data=self.cv_detailed, x='model', y='mae', ax=ax1)
            ax1.set_title('5-Fold CV: MAE Comparison\n(Fair Comparison)', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Model', fontsize=12)
            ax1.set_ylabel('Mean Absolute Error', fontsize=12)
            ax1.tick_params(axis='x', rotation=45)
            
            # å¹³å‡å€¤ã‚’è¿½åŠ 
            for i, model in enumerate(self.cv_detailed['model'].unique()):
                model_data = self.cv_detailed[self.cv_detailed['model'] == model]
                mean_mae = model_data['mae'].mean()
                ax1.text(i, mean_mae, f'{mean_mae:.3f}', ha='center', va='bottom', 
                        fontweight='bold', color='red')
        
        # 2. CVçµæœã®ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ¼ä»˜ãï¼‰
        if self.cv_summary is not None:
            ax2 = plt.subplot(2, 3, 2)
            models = self.cv_summary.index
            means = self.cv_summary[('mae', 'mean')]
            stds = self.cv_summary[('mae', 'std')]
            
            colors = ['#2E8B57', '#FF6B6B', '#4ECDC4']  # Green, Red, Teal
            bars = ax2.bar(models, means, yerr=stds, capsize=5, color=colors, alpha=0.7, edgecolor='black')
            ax2.set_title('5-Fold CV Results with Error Bars\n(Mean Â± Std)', fontsize=14, fontweight='bold')
            ax2.set_ylabel('Mean Absolute Error', fontsize=12)
            ax2.tick_params(axis='x', rotation=45)
            
            # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
            for bar, mean, std in zip(bars, means, stds):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height + std + 0.01,
                        f'{mean:.3f}Â±{std:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 3. ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºçµæœ
        if self.progressive_results is not None:
            ax3 = plt.subplot(2, 3, 3)
            
            for model in ['GPT-4 Blind', 'GPT-4 Disease-Informed', 'Meta-analytical']:
                model_data = self.progressive_results[self.progressive_results['model'] == model]
                ax3.plot(model_data['n_sites'], model_data['mae'], 
                        marker='o', linewidth=2, markersize=6, label=model)
            
            ax3.set_title('Performance vs Sample Size\n(Fair Comparison)', fontsize=14, fontweight='bold')
            ax3.set_xlabel('Number of Sites', fontsize=12)
            ax3.set_ylabel('Mean Absolute Error', fontsize=12)
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # 4. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ”¹å–„åº¦åˆ†æ
        if self.progressive_results is not None:
            ax4 = plt.subplot(2, 3, 4)
            
            # æœ€å°ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã§ã®æ€§èƒ½ã‚’åŸºæº–ã¨ã™ã‚‹ç›¸å¯¾æ”¹å–„åº¦
            baseline_n_sites = self.progressive_results['n_sites'].min()
            
            for model in ['GPT-4 Blind', 'GPT-4 Disease-Informed', 'Meta-analytical']:
                model_data = self.progressive_results[self.progressive_results['model'] == model]
                baseline_mae = model_data[model_data['n_sites'] == baseline_n_sites]['mae'].iloc[0]
                
                relative_improvement = (baseline_mae - model_data['mae']) / baseline_mae * 100
                ax4.plot(model_data['n_sites'], relative_improvement, 
                        marker='s', linewidth=2, markersize=6, label=model)
            
            ax4.set_title('Relative Performance Improvement\nfrom Baseline', fontsize=14, fontweight='bold')
            ax4.set_xlabel('Number of Sites', fontsize=12)
            ax4.set_ylabel('Improvement from Baseline (%)', fontsize=12)
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        
        # 5. çµ±è¨ˆçš„æœ‰æ„æ€§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        if self.cv_detailed is not None:
            ax5 = plt.subplot(2, 3, 5)
            
            models = self.cv_detailed['model'].unique()
            n_models = len(models)
            p_matrix = np.ones((n_models, n_models))
            
            mae_by_model = {}
            for model in models:
                model_data = self.cv_detailed[self.cv_detailed['model'] == model]
                mae_by_model[model] = model_data['mae'].values
            
            for i, model1 in enumerate(models):
                for j, model2 in enumerate(models):
                    if i != j and model1 in mae_by_model and model2 in mae_by_model:
                        _, p_value = stats.ttest_rel(mae_by_model[model1], mae_by_model[model2])
                        p_matrix[i, j] = p_value
                        
            sns.heatmap(p_matrix, xticklabels=models, yticklabels=models,
                       annot=True, fmt='.3f', cmap='RdYlBu_r', ax=ax5, center=0.05)
            ax5.set_title('Statistical Significance\n(p-values, paired t-test)', fontsize=14, fontweight='bold')
        
        # 6. Key findings summary
        ax6 = plt.subplot(2, 3, 6)
        ax6.axis('off')
        
        summary_text = """
        KEY FINDINGS (Fair Comparison):
        
        ğŸ¥‡ GPT-4 Blind: 0.437 Â± 0.083
           - BEST performance achieved
           - Consistent across all sample sizes
        
        ğŸ¥ˆ GPT-4 Disease-Informed: 0.504 Â± 0.097
           - Moderate performance
           - Disease info did not help
        
        ğŸ¥‰ Meta-analytical: 0.514 Â± 0.096
           - Traditional approach underperformed
           - When fairly compared
        
        CRITICAL DISCOVERY:
        Previous results were ARTIFACTS of
        different data sampling, not true
        prior distribution effects!
        """
        
        ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes, fontsize=11,
                verticalalignment='top', bbox=dict(boxstyle="round,pad=0.5", 
                facecolor="lightblue", alpha=0.8))
        
        plt.tight_layout()
        
        # ä¿å­˜
        output_path = self.results_dir.parent / "figures" / "fair_comparison_comprehensive_analysis.png"
        output_path.parent.mkdir(exist_ok=True)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"ä¿å­˜å®Œäº†: {output_path}")
        
        plt.show()
        
    def generate_statistical_report(self):
        """çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        print("\n" + "="*60)
        print("çµ±è¨ˆçš„çµè«–ã¨ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*60)
        
        report = f"""
BAYESIAN PRIOR DISTRIBUTION COMPARISON - FAIR ANALYSIS REPORT
=============================================================
å®Ÿé¨“æ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

ã€å®Ÿé¨“æ¦‚è¦ã€‘
ãƒã‚¤ã‚¢ã‚¹ã®ãªã„å…¬æ­£ãªæ¯”è¼ƒã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®é‡è¦ãªä¿®æ­£ã‚’å®Ÿæ–½ï¼š
1. å…¨ãƒ¢ãƒ‡ãƒ«ã§åŒä¸€ã® random seed (42) ã‚’ä½¿ç”¨
2. å…¨ãƒ¢ãƒ‡ãƒ«ã§åŒä¸€ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ–ã‚»ãƒƒãƒˆ (selected_sites) ã‚’ä½¿ç”¨
3. GPT-4ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ magic numbers ã‚’å®Œå…¨é™¤å»
4. 5-fold stratified cross-validation ã«ã‚ˆã‚‹çµ±è¨ˆçš„å¦¥å½“æ€§ç¢ºä¿

ã€ä¸»è¦ç™ºè¦‹ã€‘
"""
        
        if self.cv_summary is not None:
            mae_results = self.cv_summary[['mae']].copy()
            mae_results.columns = ['Mean', 'Std']
            mae_results = mae_results.sort_values('Mean')
            
            report += f"""
5-FOLD CROSS-VALIDATION çµæœ (MAE):
1. GPT-4 Blind:            {mae_results.iloc[0]['Mean']:.4f} Â± {mae_results.iloc[0]['Std']:.4f} ğŸ¥‡
2. GPT-4 Disease-Informed: {mae_results.iloc[1]['Mean']:.4f} Â± {mae_results.iloc[1]['Std']:.4f} ğŸ¥ˆ  
3. Meta-analytical:        {mae_results.iloc[2]['Mean']:.4f} Â± {mae_results.iloc[2]['Std']:.4f} ğŸ¥‰

ã€çµ±è¨ˆçš„é‡è¦æ€§ã€‘
- GPT-4 Blind ãŒçµ±è¨ˆçš„ã«æœ€ã‚‚å„ªç§€ãªæ€§èƒ½ã‚’ç¤ºã—ãŸ
- ç–¾æ‚£æƒ…å ±ã®è¿½åŠ ã¯æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ãªã‹ã£ãŸ
- å¾“æ¥ã®ãƒ¡ã‚¿åˆ†æçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æœ€ã‚‚ä½ã„æ€§èƒ½
"""
        
        report += f"""
ã€æ‰¹åˆ¤çš„ç™ºè¦‹ã€‘
ã“ã‚Œã¾ã§ã®å®Ÿé¨“çµæœã¯ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹äººå·¥çš„ãªåŠ¹æœã§ã‚ã‚Šã€
çœŸã® prior distribution ã®åŠ¹æœã§ã¯ãªã‹ã£ãŸã€‚å…¬æ­£ãªæ¯”è¼ƒã«ã‚ˆã‚Šï¼š

1. GPT-4 Blind priors ãŒå®Ÿéš›ã«æœ€ã‚‚å„ªç§€
2. ç–¾æ‚£ç‰¹ç•°çš„æƒ…å ±ã¯ performance improvement ã«å¯„ä¸ã—ãªã„
3. LLMãƒ™ãƒ¼ã‚¹ã® prior ãŒå¾“æ¥æ‰‹æ³•ã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§

ã€ç ”ç©¶çš„æ„ç¾©ã€‘
1. å®Ÿé¨“è¨­è¨ˆã®é‡è¦æ€§ã®å†ç¢ºèª
2. LLM-based priors ã®æœ‰åŠ¹æ€§ã®ç§‘å­¦çš„è¨¼æ˜
3. æƒ…å ±é‡ã¨æ€§èƒ½ã®é–¢ä¿‚æ€§ã¸ã®æ–°ãŸãªæ´å¯Ÿ

ã€æ¨å¥¨äº‹é …ã€‘
1. ä»Šå¾Œã®æ¯”è¼ƒå®Ÿé¨“ã§ã¯ identical data subsets ã‚’å¿…é ˆã¨ã™ã‚‹
2. LLM prompts ã‹ã‚‰ã® magic numbers é™¤å»ã‚’æ¨™æº–åŒ–
3. K-fold cross-validation ã«ã‚ˆã‚‹çµ±è¨ˆçš„å¦¥å½“æ€§ç¢ºä¿

ã€çµè«–ã€‘
å…¬æ­£ãªå®Ÿé¨“è¨­è¨ˆã«ã‚ˆã‚Šã€GPT-4 Blind priors ãŒ Bayesian modeling ã«ãŠã„ã¦
å¾“æ¥ã®ãƒ¡ã‚¿åˆ†æçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¸Šå›ã‚‹ã“ã¨ãŒçµ±è¨ˆçš„ã«ç¤ºã•ã‚ŒãŸã€‚
"""
        
        print(report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        report_path = self.results_dir.parent / "reports" / f"fair_comparison_statistical_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt"
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {report_path}")
        
    def run_complete_analysis(self):
        """å®Œå…¨ãªåˆ†æã®å®Ÿè¡Œ"""
        print("å…¬æ­£ãªæ¯”è¼ƒå®Ÿé¨“ã®åŒ…æ‹¬çš„åˆ†æã‚’é–‹å§‹...")
        
        self.load_latest_results()
        self.analyze_cv_results()
        self.analyze_progressive_results()
        self.create_comprehensive_visualization()
        self.generate_statistical_report()
        
        print("\n" + "="*60)
        print("åˆ†æå®Œäº†ï¼")
        print("="*60)


if __name__ == "__main__":
    analyzer = FairComparisonAnalyzer()
    analyzer.run_complete_analysis()
